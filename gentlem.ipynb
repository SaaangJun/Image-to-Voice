{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86db7375-8932-4e2d-b1d9-8728e673f26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (4.28.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from transformers) (2023.5.5)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: requests in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from transformers) (2.29.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from transformers) (1.23.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from transformers) (3.12.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from requests->transformers) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from requests->transformers) (1.26.15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (2.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from datasets) (1.23.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from datasets) (2023.5.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from datasets) (23.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from datasets) (12.0.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from datasets) (0.14.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from datasets) (2.0.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from datasets) (2.29.0)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from requests>=2.19.0->datasets) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
      "Requirement already satisfied: colorama in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (0.1.99)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from evaluate) (0.14.1)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from evaluate) (2.12.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from evaluate) (4.65.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from evaluate) (3.2.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from evaluate) (2023.5.0)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from evaluate) (2.0.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from evaluate) (23.0)\n",
      "Requirement already satisfied: dill in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from evaluate) (0.3.6)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from evaluate) (0.70.14)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from evaluate) (1.23.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from evaluate) (2.29.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from datasets>=2.0.0->evaluate) (12.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.8.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from requests>=2.19.0->evaluate) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from requests>=2.19.0->evaluate) (1.26.15)\n",
      "Requirement already satisfied: colorama in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from pandas->evaluate) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sacrebleu in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: regex in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from sacrebleu) (2023.5.5)\n",
      "Requirement already satisfied: lxml in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from sacrebleu) (4.9.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: portalocker in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from sacrebleu) (2.7.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from sacrebleu) (1.23.1)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from portalocker->sacrebleu) (305.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install sentencepiece\n",
    "!pip install evaluate\n",
    "!pip install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "968d79a8-9ed0-45bb-b0d9-f4b7233b0c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "007de241-bb6f-468f-aef4-b4b660401403",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Anaconda3\\envs\\fkgpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48ef13ca-7753-48ea-ac4b-f4373a20f416",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/PC/.cache/huggingface/datasets/bongsoo___csv/bongsoo--news_talk_en_ko-e7f00bc8f76f18d5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "100%|██████████| 1/1 [00:00<00:00, 50.17it/s]\n"
     ]
    }
   ],
   "source": [
    "en_ko = load_dataset(\"bongsoo/news_talk_en_ko\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3bc4a75-9996-46bf-80a6-7e842fa01315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: [\"Skinner's reward is mostly eye-watering.\", '스키너가 말한 보상은 대부분 눈으로 볼 수 있는 현물이다.'],\n",
       "        num_rows: 1299999\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab82d2f1-8f69-40e6-812c-0d82a169ce91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skinner's reward is mostly eye-watering.</th>\n",
       "      <th>스키너가 말한 보상은 대부분 눈으로 볼 수 있는 현물이다.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Even some problems can be predicted.</td>\n",
       "      <td>심지어 어떤 문제가 발생할 건지도 어느 정도 예측이 가능하다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Only God will exactly know why.</td>\n",
       "      <td>오직 하나님만이 그 이유를 제대로 알 수 있을 겁니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Businesses should not overlook China's dispute.</td>\n",
       "      <td>중국의 논쟁을 보며 간과해선 안 될 게 기업들의 고충이다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Slow-beating songs often float over time.</td>\n",
       "      <td>박자가 느린 노래는 오랜 시간이 지나 뜨는 경우가 있다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I can't even consider uninsured treatments.</td>\n",
       "      <td>보험 처리가 안 되는 비급여 시술은 엄두도 못 낸다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Skinner's reward is mostly eye-watering.   \n",
       "0             Even some problems can be predicted.  \\\n",
       "1                  Only God will exactly know why.   \n",
       "2  Businesses should not overlook China's dispute.   \n",
       "3        Slow-beating songs often float over time.   \n",
       "4      I can't even consider uninsured treatments.   \n",
       "\n",
       "     스키너가 말한 보상은 대부분 눈으로 볼 수 있는 현물이다.  \n",
       "0  심지어 어떤 문제가 발생할 건지도 어느 정도 예측이 가능하다.  \n",
       "1      오직 하나님만이 그 이유를 제대로 알 수 있을 겁니다.  \n",
       "2    중국의 논쟁을 보며 간과해선 안 될 게 기업들의 고충이다.  \n",
       "3     박자가 느린 노래는 오랜 시간이 지나 뜨는 경우가 있다.  \n",
       "4       보험 처리가 안 되는 비급여 시술은 엄두도 못 낸다.  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "en_ko.set_format(type=\"pandas\")\n",
    "df = en_ko[\"train\"][:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d726d3b9-4f66-4f3d-8712-74e2f0be7fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>ko</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skinner's reward is mostly eye-watering.</td>\n",
       "      <td>스키너가 말한 보상은 대부분 눈으로 볼 수 있는 현물이다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Even some problems can be predicted.</td>\n",
       "      <td>심지어 어떤 문제가 발생할 건지도 어느 정도 예측이 가능하다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Only God will exactly know why.</td>\n",
       "      <td>오직 하나님만이 그 이유를 제대로 알 수 있을 겁니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Businesses should not overlook China's dispute.</td>\n",
       "      <td>중국의 논쟁을 보며 간과해선 안 될 게 기업들의 고충이다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Slow-beating songs often float over time.</td>\n",
       "      <td>박자가 느린 노래는 오랜 시간이 지나 뜨는 경우가 있다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                en   \n",
       "0         Skinner's reward is mostly eye-watering.  \\\n",
       "1             Even some problems can be predicted.   \n",
       "2                  Only God will exactly know why.   \n",
       "3  Businesses should not overlook China's dispute.   \n",
       "4        Slow-beating songs often float over time.   \n",
       "\n",
       "                                   ko  \n",
       "0    스키너가 말한 보상은 대부분 눈으로 볼 수 있는 현물이다.  \n",
       "1  심지어 어떤 문제가 발생할 건지도 어느 정도 예측이 가능하다.  \n",
       "2      오직 하나님만이 그 이유를 제대로 알 수 있을 겁니다.  \n",
       "3    중국의 논쟁을 보며 간과해선 안 될 게 기업들의 고충이다.  \n",
       "4     박자가 느린 노래는 오랜 시간이 지나 뜨는 경우가 있다.  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_0 = list(df.columns)\n",
    "example_0\n",
    "example_0_df = pd.DataFrame({col: [value] for col, value in zip(('en', 'ko'), example_0)})\n",
    "df.columns = ('en', 'ko')\n",
    "en_ko_df = pd.concat([example_0_df, df],).reset_index(drop=True)\n",
    "en_ko_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19d8e7e6-386c-4ccb-9f89-aecb5176a853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['en', 'ko'],\n",
       "    num_rows: 1300000\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "dataset = Dataset.from_pandas(en_ko_df)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c43d07d-2917-4cb2-860b-2171a8c42b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = 1200000\n",
    "num_valid = 90000\n",
    "num_test = 10000\n",
    "en_ko_df_train = en_ko_df.iloc[:num_train]\n",
    "en_ko_df_valid = en_ko_df.iloc[num_train:num_train+num_valid]\n",
    "en_ko_df_test = en_ko_df.iloc[-num_test:]\n",
    "en_ko_df_train.to_csv(\"train.tsv\", sep='\\t', index=False)\n",
    "en_ko_df_valid.to_csv(\"valid.tsv\", sep='\\t', index=False)\n",
    "en_ko_df_test.to_csv(\"test.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "623830c5-6bc1-4cc9-9055-f30d136d89c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:/Users/PC/.cache/huggingface/datasets/csv/default-9b2c24984fac7a62/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 3/3 [00:00<?, ?it/s]\n",
      "Extracting data files: 100%|██████████| 3/3 [00:00<00:00, 376.29it/s]\n",
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:/Users/PC/.cache/huggingface/datasets/csv/default-9b2c24984fac7a62/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 62.71it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['en', 'ko'],\n",
       "        num_rows: 1200000\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['en', 'ko'],\n",
       "        num_rows: 90000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['en', 'ko'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files = {\"train\": \"train.tsv\", \"valid\": \"valid.tsv\", \"test\": \"test.tsv\"}\n",
    "dataset =  load_dataset(\"csv\", data_files=data_files, delimiter=\"\\t\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7870ba88-d9eb-4e98-936d-2d1b61c376e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Skinner's reward is mostly eye-watering.\", 'Even some problems can be predicted.', 'Only God will exactly know why.'] ['스키너가 말한 보상은 대부분 눈으로 볼 수 있는 현물이다.', '심지어 어떤 문제가 발생할 건지도 어느 정도 예측이 가능하다.', '오직 하나님만이 그 이유를 제대로 알 수 있을 겁니다.']\n",
      "[\"Skinner's reward is mostly eye-watering.\", 'Even some problems can be predicted.', 'Only God will exactly know why.'] ['스키너가 말한 보상은 대부분 눈으로 볼 수 있는 현물이다.', '심지어 어떤 문제가 발생할 건지도 어느 정도 예측이 가능하다.', '오직 하나님만이 그 이유를 제대로 알 수 있을 겁니다.']\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train']['en'][:3], dataset['train']['ko'][:3])\n",
    "print(dataset['train'][:3]['en'], dataset['train'][:3]['ko'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20d0bab6-1d31-4851-ab4d-2acfe1ad324c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca44d08b-49c9-418f-9e82-0c242d36060c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from datasets import load_dataset, load_metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f6d2b1d-2280-459b-93b0-153b1f1a5d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3725b94-6ac8-435c-9d7c-c0ed50328814",
   "metadata": {},
   "outputs": [],
   "source": [
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b07a9ce-6a0b-408f-a6e8-0194c5c794e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3070'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import multiprocessing\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd299580-ac9a-42b0-9b32-5031731b29bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47492cc5-1b60-4513-9c4b-52b18330048e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4388e12-61be-4a41-b213-7cd29d06862c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'토크나이저를 로딩할때 `sentencepiece`가 없다고 에러가 나면 위 제시한 라이브러리가 설치 안된 것이므로 설치하고 다시 시도한다.\\n\\n토크나이저를 불러왔으니 현재 사용하는 데이터셋에서 샘플을 가져와 토크나이징해보는 것이 좋을 것이다. 학습 세트에서 10번 샘플을 가지고 실험해보자. 먼저 10번 샘플을 뿌려보고\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_ckpt = \"KETI-AIR/ke-t5-base\"\n",
    "max_token_length = 64\n",
    "\n",
    "\"\"\"## Tokenizer\n",
    "\n",
    "먼저 모델 체크 포인트를 사용하여 KE-T5 모델이 학습할때 함께 사용한 토크나이저를 불러온다. 허깅페이스 트랜스포머스 라이브러리를 사용할 때 가장 핵심이 되며 익숙해지기 쉽지 않은 부분이 이 토크나이저라고 개인적으로 생각한다.\n",
    "\"\"\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "\n",
    "\"\"\"토크나이저를 로딩할때 `sentencepiece`가 없다고 에러가 나면 위 제시한 라이브러리가 설치 안된 것이므로 설치하고 다시 시도한다.\n",
    "\n",
    "토크나이저를 불러왔으니 현재 사용하는 데이터셋에서 샘플을 가져와 토크나이징해보는 것이 좋을 것이다. 학습 세트에서 10번 샘플을 가지고 실험해보자. 먼저 10번 샘플을 뿌려보고\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b19a5e2a-950c-4e94-9a95-82e6dc0215f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Any academic achievement requires constant repetition.',\n",
       " '어떤 학문이든지 일정의 성취를 이루기 위해서는 끊임없는 반복이 필요하다.')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset['train'][10]['en'], dataset['train'][10]['ko']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c9968cb-c111-44f8-b89e-01336cb4c29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [13941, 10114, 25542, 9361, 20526, 742, 32268, 12520, 3, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sample_en = tokenizer(dataset['train'][10]['en'], \n",
    "                                max_length=max_token_length, \n",
    "                                padding=True, truncation=True)\n",
    "tokenized_sample_en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c15fa67-8dc7-4d31-b735-1348b487d9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [404, 12663, 15, 10775, 2334, 6, 15757, 21, 29819, 1736, 26778, 4342, 15, 1701, 3, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tokenized_sample_ko = tokenizer(dataset['train'][10]['ko'], \n",
    "                                max_length=max_token_length, \n",
    "                                padding=True, truncation=True)\n",
    "tokenized_sample_ko\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43af17a8-5a23-4d04-8621-af52f8b1ec88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ids</th>\n",
       "      <td>404</td>\n",
       "      <td>12663</td>\n",
       "      <td>15</td>\n",
       "      <td>10775</td>\n",
       "      <td>2334</td>\n",
       "      <td>6</td>\n",
       "      <td>15757</td>\n",
       "      <td>21</td>\n",
       "      <td>29819</td>\n",
       "      <td>1736</td>\n",
       "      <td>26778</td>\n",
       "      <td>4342</td>\n",
       "      <td>15</td>\n",
       "      <td>1701</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁어떤</td>\n",
       "      <td>▁학문</td>\n",
       "      <td>이</td>\n",
       "      <td>든지</td>\n",
       "      <td>▁일정</td>\n",
       "      <td>의</td>\n",
       "      <td>▁성취</td>\n",
       "      <td>를</td>\n",
       "      <td>▁이루기</td>\n",
       "      <td>▁위해서는</td>\n",
       "      <td>▁끊임없는</td>\n",
       "      <td>▁반복</td>\n",
       "      <td>이</td>\n",
       "      <td>▁필요하다</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1   2      3     4  5      6   7      8      9      10    11   \n",
       "ids     404  12663  15  10775  2334  6  15757  21  29819   1736  26778  4342  \\\n",
       "tokens  ▁어떤    ▁학문   이     든지   ▁일정  의    ▁성취   를   ▁이루기  ▁위해서는  ▁끊임없는   ▁반복   \n",
       "\n",
       "        12     13 14    15  \n",
       "ids     15   1701  3     1  \n",
       "tokens   이  ▁필요하다  .  </s>  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tokenizer(dataset['train'][:3]['en'], \n",
    "          max_length=max_token_length, \n",
    "          padding=True, truncation=True)\n",
    "\n",
    "\"\"\"미니배치에 있는 샘플의 최대길이메 맞춰서 패딩되는 모습을 확인할 수 있다. 실제로 어떻게 토큰화 되었는지 확인해보자.\"\"\"\n",
    "\n",
    "pd.DataFrame(\n",
    "    [\n",
    "        tokenized_sample_en['input_ids'],\n",
    "        tokenizer.convert_ids_to_tokens(tokenized_sample_en['input_ids'])\n",
    "    ], index=('ids', 'tokens')\n",
    ")\n",
    "\n",
    "pd.DataFrame(\n",
    "    [\n",
    "        tokenized_sample_ko['input_ids'],\n",
    "        tokenizer.convert_ids_to_tokens(tokenized_sample_ko['input_ids'])\n",
    "    ], index=('ids', 'tokens')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ecc6b9b2-0aa9-4ed0-a8b5-bbba5415866a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(examples):\n",
    "    model_inputs = tokenizer(examples['en'],\n",
    "                             text_target=examples['ko'], \n",
    "                             max_length=max_token_length, truncation=True)\n",
    "    \n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0133828-6aba-4e05-903b-836423614b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples= {'en':['sent1', 'sent2', ... , 'sent1000'], # 이건 문장 1000개짜리 리스트\n",
    "           'ko':['sent1', 'sent2', ... , 'sent1000']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "192e5ddc-75f5-4c6f-9a4e-25ee663c934f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CPU = multiprocessing.cpu_count() \n",
    "NUM_CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90d136b0-66b6-448f-9563-f4f71f56ac52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"그리고 `remove_columns` 인자에 기존 특성 이름인 `en`, `ko`를 전달해서 기존 특성은 제거하게 한다. 이 특성이 있으면 이후 콜레이터가 샘플들을 미니 배치로 묶을 때 패딩처리를 못하게 된다. \"\"\"\n",
    "\n",
    "                              #  num_proc=NUM_CPU)\n",
    "tokenized_datasets = dataset.map(\n",
    "    convert_examples_to_features,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c66fc222-ca0d-48f4-92f8-ddae0e89a88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1200000\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 90000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e4ef885-79ae-4879-a4cc-7f21b55477d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [13941, 10114, 25542, 9361, 20526, 742, 32268, 12520, 3, 1],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 'labels': [404,\n",
       "  12663,\n",
       "  15,\n",
       "  10775,\n",
       "  2334,\n",
       "  6,\n",
       "  15757,\n",
       "  21,\n",
       "  29819,\n",
       "  1736,\n",
       "  26778,\n",
       "  4342,\n",
       "  15,\n",
       "  1701,\n",
       "  3,\n",
       "  1]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['train'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e745e413-1f59-40fd-a20f-77af7b70d119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원 데이터    : Any academic achievement requires constant repetition.\n",
      "처리 후 데이터: [13941, 10114, 25542, 9361, 20526, 742, 32268, 12520, 3, 1]\n",
      "토큰화       : ['▁Any', '▁academic', '▁achievement', '▁requires', '▁constant', '▁re', 'pet', 'ition', '.', '</s>']\n",
      "\n",
      "\n",
      "원 데이터    : 어떤 학문이든지 일정의 성취를 이루기 위해서는 끊임없는 반복이 필요하다.\n",
      "처리 후 데이터: ['▁어떤', '▁학문', '이', '든지', '▁일정', '의', '▁성취', '를', '▁이루기', '▁위해서는', '▁끊임없는', '▁반복', '이', '▁필요하다', '.', '</s>']\n",
      "토큰화       : [404, 12663, 15, 10775, 2334, 6, 15757, 21, 29819, 1736, 26778, 4342, 15, 1701, 3, 1]\n"
     ]
    }
   ],
   "source": [
    "print( '원 데이터    :', dataset['train'][10]['en'] )\n",
    "print( '처리 후 데이터:', tokenized_datasets['train'][10]['input_ids'] )\n",
    "print( '토큰화       :', tokenizer.convert_ids_to_tokens(tokenized_datasets['train'][10]['input_ids']) )\n",
    "\n",
    "print('\\n')\n",
    "print( '원 데이터    :', dataset['train'][10]['ko'] )\n",
    "print( '처리 후 데이터:', tokenizer.convert_ids_to_tokens(tokenized_datasets['train'][10]['labels']) )\n",
    "print( '토큰화       :', tokenized_datasets['train'][10]['labels'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6df6914-7cbc-403b-8e50-b945ad6c16a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a522205-e2dc-48de-a5c5-ec2055735f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = tokenizer(\n",
    "    [\"Studies have been shown that owning a dog is good for you\"], \n",
    "    return_tensors=\"pt\"\n",
    ")['input_ids'].to(device)\n",
    "\n",
    "decoder_targets = tokenizer(\n",
    "    [\"개를 키우는 것이 건강에 좋다는 연구 결과가 있습니다.\"], \n",
    "    return_tensors=\"pt\"\n",
    ")['input_ids'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c11cefa8-e96f-4d34-8c7e-c83f052cc76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[24611,    84,   166,  8135,    38,   847,    91,    16,  8146,    43,\n",
      "           667,    40,   106,     1]], device='cuda:0')\n",
      "tensor([[15833, 12236,   179, 16120, 28117,  1007,  3883,   327,     3,     1]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print( encoder_inputs )\n",
    "print( decoder_targets )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "48c09cc2-507c-4784-b996-a43f0c72297d",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = model._shift_right(decoder_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b403b71d-7438-4b5d-92d4-f32baff6aeee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>decoder target</th>\n",
       "      <td>▁개를</td>\n",
       "      <td>▁키우는</td>\n",
       "      <td>▁것이</td>\n",
       "      <td>▁건강에</td>\n",
       "      <td>▁좋다는</td>\n",
       "      <td>▁연구</td>\n",
       "      <td>▁결과가</td>\n",
       "      <td>▁있습니다</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder input</th>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>▁개를</td>\n",
       "      <td>▁키우는</td>\n",
       "      <td>▁것이</td>\n",
       "      <td>▁건강에</td>\n",
       "      <td>▁좋다는</td>\n",
       "      <td>▁연구</td>\n",
       "      <td>▁결과가</td>\n",
       "      <td>▁있습니다</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0     1     2     3     4     5     6      7      8     9\n",
       "decoder target    ▁개를  ▁키우는   ▁것이  ▁건강에  ▁좋다는   ▁연구  ▁결과가  ▁있습니다      .  </s>\n",
       "decoder input   <pad>   ▁개를  ▁키우는   ▁것이  ▁건강에  ▁좋다는   ▁연구   ▁결과가  ▁있습니다     ."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    [\n",
    "        tokenizer.convert_ids_to_tokens(decoder_targets[0]),\n",
    "        tokenizer.convert_ids_to_tokens(decoder_inputs[0])\n",
    "    ],\n",
    "    index=('decoder target', 'decoder input')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ec99756f-5886-4c4c-847b-69e6ab69a543",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(input_ids=encoder_inputs, \n",
    "                decoder_input_ids=decoder_inputs, \n",
    "                labels=decoder_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "08b69ff5-eb15-4695-97d8-e3f1a476980a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['loss', 'logits', 'past_key_values', 'encoder_last_hidden_state'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed014e79-8f0b-4936-b6c9-414d4b2fe93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(87.8281, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "852ee80b-7a6b-4bf9-a9c9-4ee931adc0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 14, 768])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs['encoder_last_hidden_state'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "df484d9c-0cfb-4c86-924e-a0a113741983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 64128])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs['logits'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3de2f1e7-4038-4745-9478-9ec3f71d0eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['큐브', '큐브', '▁비일비재', '▁비일비재', '▁베네', '▁비일비재', '▁베네', '▁베네', '큐브', '큐브']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens( torch.argmax(outputs['logits'][0], axis=1).cpu().numpy() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9e2e7612-6c75-4dd9-aaf0-c6c16550ea2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[4014, 322, 3170, 147, 67, 23274, 3, 1],\n",
       "  [11783, 4412, 96, 6556, 709, 1632, 3, 1]],\n",
       " 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " 'labels': [[6842, 404, 951, 5767, 15387, 27, 831, 800, 4378, 15, 1587, 3, 1],\n",
       "  [9881, 18590, 3837, 70, 4341, 1086, 677, 35, 426, 2255, 3, 1]]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "tokenized_datasets[\"train\"][1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "28a12951-942c-464b-a4cd-a5aa9f7f6248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input_ids': [4014, 322, 3170, 147, 67, 23274, 3, 1],\n",
       "  'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  'labels': [6842, 404, 951, 5767, 15387, 27, 831, 800, 4378, 15, 1587, 3, 1]},\n",
       " {'input_ids': [11783, 4412, 96, 6556, 709, 1632, 3, 1],\n",
       "  'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  'labels': [9881, 18590, 3837, 70, 4341, 1086, 677, 35, 426, 2255, 3, 1]}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenized_datasets[\"train\"][i] for i in range(1, 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ccdbc27-004c-4caa-b211-b75e70b41fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "batch = data_collator(\n",
    "    [tokenized_datasets[\"train\"][i] for i in range(1, 3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "192118fc-70f1-44d3-9fdc-fc550ebd96dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'labels', 'decoder_input_ids'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0be6ac86-03a2-4078-b141-e8162466995b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 4014,   322,  3170,   147,    67, 23274,     3,     1],\n",
       "        [11783,  4412,    96,  6556,   709,  1632,     3,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[ 6842,   404,   951,  5767, 15387,    27,   831,   800,  4378,    15,\n",
       "          1587,     3,     1],\n",
       "        [ 9881, 18590,  3837,    70,  4341,  1086,   677,    35,   426,  2255,\n",
       "             3,     1,  -100]]), 'decoder_input_ids': tensor([[    0,  6842,   404,   951,  5767, 15387,    27,   831,   800,  4378,\n",
       "            15,  1587,     3],\n",
       "        [    0,  9881, 18590,  3837,    70,  4341,  1086,   677,    35,   426,\n",
       "          2255,     3,     1]])}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "219d1f73-10ce-44f4-a958-f376d7723f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "53bd9281-99ca-4cc7-b471-1bdb7cf169f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 100.00000000000004,\n",
       " 'counts': [21, 19, 17, 15],\n",
       " 'totals': [21, 19, 17, 15],\n",
       " 'precisions': [100.0, 100.0, 100.0, 100.0],\n",
       " 'bp': 1.0,\n",
       " 'sys_len': 21,\n",
       " 'ref_len': 21}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = [\n",
    "    \"저는 딥러닝을 좋아해요.\",\n",
    "    \"요즘은 딥러닝 프레임워크가 잘 발달되어 있기 때문에 누구의 도움 없이도 기계 번역 시스템을 구축할 수 있습니다.\"\n",
    "]\n",
    "\n",
    "references = [\n",
    "    [\"저는 딥러닝을 좋아해요.\", \"나는 딥러닝을 사랑해요.\"],\n",
    "    [\"요즘은 딥러닝 프레임워크가 잘 발달되어 있기 때문에 누구의 도움 없이도 기계 번역 시스템을 구축할 수 있습니다.\",\n",
    "     \"최근에는 딥러닝 프레임워크가 잘 개발되어 있기 때문에 다른 사람의 도움 없이도 기계 번역 시스템을 개발할 수 있습니다.\"]\n",
    "]\n",
    "metric.compute(predictions=predictions, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "02682ceb-d579-4969-b603-a6281dac7756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 25.28116160010779,\n",
       " 'counts': [14, 7, 4, 1],\n",
       " 'totals': [19, 17, 15, 13],\n",
       " 'precisions': [73.6842105263158,\n",
       "  41.1764705882353,\n",
       "  26.666666666666668,\n",
       "  7.6923076923076925],\n",
       " 'bp': 0.9000876262522591,\n",
       " 'sys_len': 19,\n",
       " 'ref_len': 21}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = [\n",
    "    \"저는 딥러닝을 좋아해요.\",\n",
    "    \"딥러닝 프레임워크가 잘 개발되었기 때문에 요즘은 누군가의 도움 없이 기계번역 시스템을 구축할 수 있다.\"\n",
    "]\n",
    "\n",
    "references = [\n",
    "    [\"저는 딥러닝을 좋아해요.\", \"나는 딥러닝을 사랑해요.\"],\n",
    "    [\"요즘은 딥러닝 프레임워크가 잘 발달되어 있기 때문에 누구의 도움 없이도 기계 번역 시스템을 구축할 수 있습니다.\",\n",
    "     \"최근에는 딥러닝 프레임워크가 잘 개발되어 있기 때문에 다른 사람의 도움 없이도 기계 번역 시스템을 개발할 수 있습니다.\"]\n",
    "]\n",
    "metric.compute(predictions=predictions, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3f92cbf5-7efd-4423-b618-bea4484bcc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    \n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    \n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    \n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Some simple post-processing\n",
    "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "    decoded_labels = [[label.strip()] for label in decoded_labels]\n",
    "    \n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3f3d018b-b186-43b0-98f9-23f0ee1543b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 4.28.0\n",
      "Uninstalling transformers-4.28.0:\n",
      "  Successfully uninstalled transformers-4.28.0\n",
      "Found existing installation: accelerate 0.19.0\n",
      "Uninstalling accelerate-0.19.0:\n",
      "  Successfully uninstalled accelerate-0.19.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-0.19.0-py3-none-any.whl (219 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from transformers) (3.12.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from transformers) (2023.5.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: requests in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from transformers) (2.29.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from transformers) (1.23.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from accelerate) (1.10.1+cu113)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from requests->transformers) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from requests->transformers) (1.26.15)\n",
      "Installing collected packages: accelerate, transformers\n",
      "Successfully installed accelerate-0.19.0 transformers-4.29.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y transformers accelerate\n",
    "!pip install transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4118d6c0-ecce-438b-89f0-66f52ed834dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.28.0 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (4.28.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from transformers==4.28.0) (0.13.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from transformers==4.28.0) (1.23.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from transformers==4.28.0) (2023.5.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from transformers==4.28.0) (23.0)\n",
      "Requirement already satisfied: requests in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from transformers==4.28.0) (2.29.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from transformers==4.28.0) (0.14.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from transformers==4.28.0) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from transformers==4.28.0) (4.65.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from transformers==4.28.0) (3.12.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (2023.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (4.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from tqdm>=4.27->transformers==4.28.0) (0.4.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from requests->transformers==4.28.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from requests->transformers==4.28.0) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from requests->transformers==4.28.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages (from requests->transformers==4.28.0) (2023.5.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\pc\\anaconda3\\envs\\fkgpu\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install transformers==4.28.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a8aec143-f907-4494-a1c4-c1dd26276bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "769"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "97034e29-c451-4e11-8437-598e142c6387",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"chkpt\",\n",
    "    learning_rate=0.0005,\n",
    "    weight_decay=0.01,\n",
    "    per_device_train_batch_size=12,\n",
    "    per_device_eval_batch_size=128,\n",
    "    num_train_epochs=1,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"no\",\n",
    "    predict_with_generate=True,\n",
    "    fp16=False,\n",
    "    gradient_accumulation_steps=2,\n",
    "    report_to=\"none\" # Wandb 로그 끄기\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a3a0d9-635b-4ac0-b754-cfd11a5cff61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1950b7ad-a900-43f4-8c19-d18fe5121aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"valid\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70213113-2512-409c-b2f1-b001b738a462",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bdd965-9b99-4dc4-a671-4a9cd3c1dfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./results2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a220a63a-ee68-4fe3-a10c-02ee0843e931",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"./results\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_dir)\n",
    "\n",
    "model.cpu();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e2a9cd6d-ce9e-45ee-9286-60c6489b5ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"./results2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_dir)\n",
    "\n",
    "model.cpu();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c0116e9d-0f0b-4b52-9529-0a4bdcb4c7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2ab8fcc7-e833-40cd-aea5-0989bd9b8f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = [\n",
    "    \"You will face many defeats in life, but never let yourself be defeated.\",\n",
    "    \"The greatest glory in living lies not in never falling, but in rising every time we fall\",\n",
    "    \"Nice to meet you,brother\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6cf494b7-984a-4770-ba4f-fa8cd0782913",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(input_text, return_tensors=\"pt\", \n",
    "                   padding=True, max_length=max_token_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5cfa852d-f024-464b-9d17-8f2a58bd6501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  988,    96,  2267,   494, 10503,     8,    20,   899,     4,   134,\n",
       "          1249,  2691,  8267,    67, 20362,     3,     1,     0,     0],\n",
       "        [   55, 12949, 45992,    20,  3144, 18635,   112,    20,  1249, 13223,\n",
       "             4,   134,    20,  9413,  1073,   248,   146,  3653,     1],\n",
       "        [51817,    10,  3391,   106,     4, 24520, 15422,     1,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b7741b68-56d4-46d9-a895-256ee9962f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 19])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "koreans = model.generate(\n",
    "    **inputs,\n",
    "    max_length=max_token_length,\n",
    "    num_beams=5,\n",
    ")\n",
    "\n",
    "koreans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "92aeb34f-0b35-488e-a8f8-ad2692274367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad> 인생에서 많은 패배를 당하겠지만, 절대 패배하지 마세요.</s><pad><pad><pad><pad><pad><pad>',\n",
       " '<pad> 살면서 가장 큰 영광은 결코 떨어지지 않는 것이 아니라 우리가 떨어질 때마다 오르는 것이에요.</s>',\n",
       " '<pad> 당신과 만나 뵙게 되어 기<unk>니다, 오빠.</s><pad><pad><pad><pad><pad>']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ \n",
    "    tokenizer.convert_tokens_to_string(\n",
    "    tokenizer.convert_ids_to_tokens(korean)) for korean in koreans\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2783db41-1ae9-4ab8-ba63-30051885e5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"test\"], batch_size=32, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0a92a634-de01-4085-9ed8-c2722eff38cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader_iter = iter(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "80100aae-9d3e-47bb-8dff-5949fdb27b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = next(test_dataloader_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dad0fbe1-dce9-49d5-a83d-4b3878c94a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'labels', 'decoder_input_ids'])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "31c06396-556e-455f-8429-b1fe1d9fc78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = { key: test_batch[key] for key in ('input_ids', 'attention_mask') }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d6be23a3-457e-4893-8d49-b6591f19751d",
   "metadata": {},
   "outputs": [],
   "source": [
    "koreans = model.generate(\n",
    "    **test_input,\n",
    "    max_length=max_token_length,\n",
    "    num_beams=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c56ce9fa-d1c5-4298-9a0e-81e200aa44ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels =  np.where(test_batch.labels != -100, test_batch.labels, tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a474a214-d6b4-4243-b870-1bf8700e2db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_sents = tokenizer.batch_decode(test_batch.input_ids, skip_special_tokens=True)[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2af17fba-3fdf-4d6a-96e7-a30406bc81f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "references = tokenizer.batch_decode(labels, skip_special_tokens=True)[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "69df5c1a-cc9b-428b-b6b9-d7528326dc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = tokenizer.batch_decode( koreans, skip_special_tokens=True )[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f759887a-d21a-4963-a615-3048398d2969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English   : Yes, I'll see you at the parking lot at 3 p.m.\n",
      "Reference : 네, 오후 3시에 주차장에서 뵙죠.\n",
      "Translated: 네, 오후 3시에 주차장에서 뵙겠습니다.\n",
      "\n",
      "\n",
      "English   : I'm happy to see Jessica Huh take over my role.\n",
      "Reference : Jessica Huh가 제 역할을 인계받게 되어서 저는 기니다.\n",
      "Translated: 제시카 허가 제 역할을 맡게 되어 기니다.\n",
      "\n",
      "\n",
      "English   : I agree with you that she is qualified for the position.\n",
      "Reference : 저도 부장님 의견대로 그녀가 이 자리의 적임자라고 생각합니다.\n",
      "Translated: 저는 그녀가 그 자리에 자격이 있다는 것에 동의합니다.\n",
      "\n",
      "\n",
      "English   : Nick, I was told that your department will be divided into two.\n",
      "Reference : Nick, 당신 부서가 둘로 나뉜다면서요?\n",
      "Translated: 닉, 당신의 부서가 두 개로 나뉘게 될 거라고 들었습니다.\n",
      "\n",
      "\n",
      "English   : Yes, all staff involved in online advertising will have their own office space located on the 2nd floor.\n",
      "Reference : 네, 다음 달 초부터 온라인 광고와 관련된 직원들은 2층에 위치한 개별 사무실 공간을 사용한다고 합니다.\n",
      "Translated: 네, 온라인 광고에 관여하는 모든 직원이 2층에 각자의 오피스 공간을 가질 것입니다.\n",
      "\n",
      "\n",
      "English   : What happens to the remaining staff?\n",
      "Reference : 남은 직원들은 어떻게 되나요?\n",
      "Translated: 남은 스태프에게 무슨 일이 생겼나요?\n",
      "\n",
      "\n",
      "English   : The remaining staff will stay in the current space on the 3rd floor, and the division will continue to be called the advertising department.\n",
      "Reference : 남은 직원들은 3층 현재 자리에 남을 것이고, 부서는 계속 광고 부서로 불린다고 하네요.\n",
      "Translated: 나머지 직원들은 현재 3층 공간에 머무르며, 이 부서는 계속 광고 부서라고 불리게 된다.\n",
      "\n",
      "\n",
      "English   : I have a question about the year-end tax adjustment.\n",
      "Reference : 이번 연말 정산 관련해서 질문이 있어요.\n",
      "Translated: 저는 연말정산에 대해 궁금한 점이 있습니다.\n",
      "\n",
      "\n",
      "English   : Is there any problem?\n",
      "Reference : 무슨 문제라도 있으신가요?\n",
      "Translated: 혹시 문제가 있나요?\n",
      "\n",
      "\n",
      "English   : I am registering my dependent this time, so do I need to submit any particular documents?\n",
      "Reference : 제가 이번에 부양가족을 등록하려고 하는데, 따로 제출해야 하는 서류가 있나요?\n",
      "Translated: 이번에 제 부양가족 등록을 하는데, 특별히 서류 제출이 필요한가요?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in zip(eng_sents, references, preds):\n",
    "    print('English   :', s[0])\n",
    "    print('Reference :', s[1])\n",
    "    print('Translated:', s[2])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583a86cd-aef6-47fc-9f8c-8b5c8f70ee55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
