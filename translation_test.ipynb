{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Collecting huggingface-hub<1.0,>=0.14.1\n",
      "  Using cached huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
      "Requirement already satisfied: requests in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp310-cp310-macosx_11_0_arm64.whl (173 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.0/174.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Using cached filelock-3.12.0-py3-none-any.whl (10 kB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2023.5.5-cp310-cp310-macosx_11_0_arm64.whl (288 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.9/288.9 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from transformers) (1.24.3)\n",
      "Collecting tqdm>=4.27\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-macosx_12_0_arm64.whl (3.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting fsspec\n",
      "  Using cached fsspec-2023.5.0-py3-none-any.whl (160 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n",
      "Installing collected packages: tokenizers, tqdm, regex, pyyaml, fsspec, filelock, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.12.0 fsspec-2023.5.0 huggingface-hub-0.14.1 pyyaml-6.0 regex-2023.5.5 tokenizers-0.13.3 tqdm-4.65.0 transformers-4.29.2\n",
      "Collecting datasets\n",
      "  Using cached datasets-2.12.0-py3-none-any.whl (474 kB)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from datasets) (4.65.0)\n",
      "Collecting responses<0.19\n",
      "  Using cached responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Collecting dill<0.3.7,>=0.3.0\n",
      "  Using cached dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from datasets) (0.14.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from datasets) (2023.5.0)\n",
      "Requirement already satisfied: packaging in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from datasets) (6.0)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.2.0-cp310-cp310-macosx_11_0_arm64.whl (31 kB)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.4-cp310-cp310-macosx_11_0_arm64.whl (336 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.9/336.9 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.0.2-cp310-cp310-macosx_11_0_arm64.whl (10.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting multiprocess\n",
      "  Using cached multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
      "Collecting pyarrow>=8.0.0\n",
      "  Downloading pyarrow-12.0.0-cp310-cp310-macosx_11_0_arm64.whl (22.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.6/22.6 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from datasets) (1.24.3)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp310-cp310-macosx_11_0_arm64.whl (34 kB)\n",
      "Collecting attrs>=17.3.0\n",
      "  Using cached attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp310-cp310-macosx_11_0_arm64.whl (29 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from aiohttp->datasets) (3.1.0)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.2-cp310-cp310-macosx_11_0_arm64.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.6.2)\n",
      "Requirement already satisfied: filelock in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Collecting tzdata>=2022.1\n",
      "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: pytz, xxhash, tzdata, pyarrow, multidict, frozenlist, dill, attrs, async-timeout, yarl, responses, pandas, multiprocess, aiosignal, aiohttp, datasets\n",
      "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 attrs-23.1.0 datasets-2.12.0 dill-0.3.6 frozenlist-1.3.3 multidict-6.0.4 multiprocess-0.70.14 pandas-2.0.2 pyarrow-12.0.0 pytz-2023.3 responses-0.18.0 tzdata-2023.3 xxhash-3.2.0 yarl-1.9.2\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.99-cp310-cp310-macosx_11_0_arm64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.99\n",
      "Collecting evaluate\n",
      "  Using cached evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from evaluate) (2.12.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from evaluate) (1.24.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from evaluate) (0.14.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from evaluate) (2023.5.0)\n",
      "Requirement already satisfied: multiprocess in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from evaluate) (0.70.14)\n",
      "Requirement already satisfied: packaging in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from evaluate) (23.1)\n",
      "Requirement already satisfied: xxhash in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from evaluate) (3.2.0)\n",
      "Requirement already satisfied: pandas in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from evaluate) (2.0.2)\n",
      "Requirement already satisfied: dill in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from evaluate) (0.3.6)\n",
      "Requirement already satisfied: responses<0.19 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from evaluate) (4.65.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (12.0.0)\n",
      "Requirement already satisfied: aiohttp in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: filelock in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.6.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.16)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Installing collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.0\n",
      "Collecting sacrebleu\n",
      "  Using cached sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
      "Collecting portalocker\n",
      "  Using cached portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: regex in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from sacrebleu) (2023.5.5)\n",
      "Collecting tabulate>=0.8.9\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/baesangjun/miniforge3/envs/DEEP/lib/python3.10/site-packages (from sacrebleu) (1.24.3)\n",
      "Collecting colorama\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Collecting lxml\n",
      "  Using cached lxml-4.9.2.tar.gz (3.7 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: lxml\n",
      "  Building wheel for lxml (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lxml: filename=lxml-4.9.2-cp310-cp310-macosx_11_0_arm64.whl size=1590551 sha256=1322e099d24727c41dc520498082da1681fa987ec958783172559e555c88c789\n",
      "  Stored in directory: /Users/baesangjun/Library/Caches/pip/wheels/5a/51/0e/95b4a6ddee4a616530c36aeb03dafb5e04183756d9973a7d5d\n",
      "Successfully built lxml\n",
      "Installing collected packages: tabulate, portalocker, lxml, colorama, sacrebleu\n",
      "Successfully installed colorama-0.4.6 lxml-4.9.2 portalocker-2.7.0 sacrebleu-2.3.1 tabulate-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install sentencepiece\n",
    "!pip install evaluate\n",
    "!pip install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "metric = evaluate.load(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"/Users/baesangjun/Desktop/SWProject/result2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_dir)\n",
    "max_token_length = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/Users/baesangjun/.cache/huggingface/datasets/bongsoo___csv/bongsoo--news_talk_en_ko-e7f00bc8f76f18d5/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ba676ba3444e8983f5d60f312ffb3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /Users/baesangjun/.cache/huggingface/datasets/csv/default-0c7f67879a7f0b04/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcd359b8950c4c7fa4b826634c51b895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7442214bb58d46c18b15870c353835f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eada82dac2844d288a265fc97274c1e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e37756d804b74226b96c9c4b39afef59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating valid split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cc7c8255f0448b995226255a7812457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /Users/baesangjun/.cache/huggingface/datasets/csv/default-0c7f67879a7f0b04/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "890bc5992dbd4e28a17c11ea8fdc0ef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "en_ko = load_dataset(\"bongsoo/news_talk_en_ko\")\n",
    "en_ko.set_format(type=\"pandas\")\n",
    "df = en_ko[\"train\"][:]\n",
    "example_0 = list(df.columns)\n",
    "example_0_df = pd.DataFrame({col: [value] for col, value in zip(('en', 'ko'), example_0)})\n",
    "df.columns = ('en', 'ko')\n",
    "en_ko_df = pd.concat([example_0_df, df],).reset_index(drop=True)\n",
    "dataset = Dataset.from_pandas(en_ko_df)\n",
    "# 각 데이터 셋의 샘플수를 정한다.\n",
    "num_train = 1200000\n",
    "num_valid = 90000\n",
    "num_test = 10000\n",
    "\n",
    "en_ko_df_train = en_ko_df.iloc[:num_train]\n",
    "en_ko_df_valid = en_ko_df.iloc[num_train:num_train+num_valid]\n",
    "en_ko_df_test = en_ko_df.iloc[-num_test:]\n",
    "\n",
    "en_ko_df_train.to_csv(\"train.tsv\", sep='\\t', index=False)\n",
    "en_ko_df_valid.to_csv(\"valid.tsv\", sep='\\t', index=False)\n",
    "en_ko_df_test.to_csv(\"test.tsv\", sep='\\t', index=False)\n",
    "\n",
    "data_files = {\"train\": \"train.tsv\", \"valid\": \"valid.tsv\", \"test\": \"test.tsv\"}\n",
    "dataset =  load_dataset(\"csv\", data_files=data_files, delimiter=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2f4dfd61ad544dca93ee05151fc2954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/1200000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24caf73d37a84d0ea293af5b4ee6cf7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/90000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae0794db876b4cc2be1604db163f3d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1200000\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 90000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ckpt = \"KETI-AIR/ke-t5-base\"\n",
    "max_token_length = 64\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_ckpt) \n",
    "\n",
    "def convert_examples_to_features(examples):\n",
    "    model_inputs = tokenizer(examples['en'],\n",
    "                             text_target=examples['ko'], \n",
    "                             max_length=max_token_length, truncation=True)\n",
    "    \n",
    "    return model_inputs\n",
    "\n",
    "NUM_CPU = multiprocessing.cpu_count() \n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(convert_examples_to_features, \n",
    "                                 batched=True, \n",
    "                                 # 이걸 쓰지 않으면 원 데이터 'en', 'ko'가 남아서\n",
    "                                 # 아래서 콜레이터가 패딩을 못해서 에러남\n",
    "                                 remove_columns=dataset[\"train\"].column_names,\n",
    "                                 num_proc=NUM_CPU) \n",
    "\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"test\"], batch_size=32, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English   : I already placed it on the express order yesterday.\n",
      "Reference : 제가 어제 이미 급송 주문으로 넣어두었습니다.\n",
      "Translated: 저는 어제 이미 급행 주문에 넣었습니다.\n",
      "\n",
      "\n",
      "English   : Did they say the items could arrive on time?\n",
      "Reference : 물건들은 제날짜에 도착할 수 있다고 하던가요?\n",
      "Translated: 그 물건들이 제때 도착할 수 있다고 했나요?\n",
      "\n",
      "\n",
      "English   : Yes, all the items will arrive the day before the new employees arrive at work.\n",
      "Reference : 네, 물건들은 새로운 직원들이 출근하기 전날에 모두 도착할 것입니다.\n",
      "Translated: 네, 신입사원이 출근하기 하루 전에 모든 물품이 도착합니다.\n",
      "\n",
      "\n",
      "English   : We need to visit their offices and do an assessment as this is potentially a large-scale project.\n",
      "Reference : 이번에는 규모가 큰 프로젝트이니, 그들의 사무실을 방문해서 조사해야 해요.\n",
      "Translated: 우리는 대규모 프로젝트일 가능성이 있는 만큼 그들의 사무실을 방문해서 평가를 해야 합니다.\n",
      "\n",
      "\n",
      "English   : Do you need me to do anything in regard to the project?\n",
      "Reference : 이 건에 대해 제가 무언가 해야 할 것이 있나요?\n",
      "Translated: 프로젝트와 관련하여 내가 무엇을 해야 하나요?\n",
      "\n",
      "\n",
      "English   : Yes, I really need your expertise.\n",
      "Reference : 네, 저는 정말로 당신의 전무 지식이 필요해요.\n",
      "Translated: 네, 나는 정말 당신의 전문지식이 필요해요.\n",
      "\n",
      "\n",
      "English   : Yes, let me know what I have to do and I'll be ready.\n",
      "Reference : 네, 제가 해야 할 일들을 알려주시면 준비하겠습니다.\n",
      "Translated: 네, 제가 무엇을 해야 하는지 알려주시면 준비하겠습니다.\n",
      "\n",
      "\n",
      "English   : What should I do?\n",
      "Reference : 제가 무슨 일을 하면 되나요?\n",
      "Translated: 제가 어떻게 해야 하나요?\n",
      "\n",
      "\n",
      "English   : I will need you to take measurements of the space and find out about particular needs, the budget, and other details.\n",
      "Reference : 당신은 공간의 치수를 재고 특별히 필요한 것, 예산 그리고 다른 세부 사항에 대해 알아봐 주셨으면 해요.\n",
      "Translated: 공간을 측정해서 특별한 요구 사항, 예산, 기타 세부사항을 알아봐 주실 필요가 있습니다.\n",
      "\n",
      "\n",
      "English   : I see, shall we leave the office together later?\n",
      "Reference : 알겠습니다, 이따가 사무실에서 같이 떠날까요?\n",
      "Translated: 제가 볼 때, 나중에 같이 사무실에 나가볼까요?\n",
      "\n",
      "\n",
      "English   : Yes, I'll see you at the parking lot at 3 p.m.\n",
      "Reference : 네, 오후 3시에 주차장에서 뵙죠.\n",
      "Translated: 네, 오후 3시에 주차장에서 뵙겠습니다.\n",
      "\n",
      "\n",
      "English   : I'm happy to see Jessica Huh take over my role.\n",
      "Reference : Jessica Huh가 제 역할을 인계받게 되어서 저는 기니다.\n",
      "Translated: 제시카 허가 제 역할을 맡게 되어 기니다.\n",
      "\n",
      "\n",
      "English   : I agree with you that she is qualified for the position.\n",
      "Reference : 저도 부장님 의견대로 그녀가 이 자리의 적임자라고 생각합니다.\n",
      "Translated: 저는 그녀가 그 자리에 자격이 있다는 것에 동의합니다.\n",
      "\n",
      "\n",
      "English   : Nick, I was told that your department will be divided into two.\n",
      "Reference : Nick, 당신 부서가 둘로 나뉜다면서요?\n",
      "Translated: 닉, 당신의 부서가 두 개로 나뉘게 될 거라고 들었습니다.\n",
      "\n",
      "\n",
      "English   : Yes, all staff involved in online advertising will have their own office space located on the 2nd floor.\n",
      "Reference : 네, 다음 달 초부터 온라인 광고와 관련된 직원들은 2층에 위치한 개별 사무실 공간을 사용한다고 합니다.\n",
      "Translated: 네, 온라인 광고에 관여하는 모든 직원이 2층에 각자의 오피스 공간을 가질 것입니다.\n",
      "\n",
      "\n",
      "English   : What happens to the remaining staff?\n",
      "Reference : 남은 직원들은 어떻게 되나요?\n",
      "Translated: 남은 스태프에게 무슨 일이 생겼나요?\n",
      "\n",
      "\n",
      "English   : The remaining staff will stay in the current space on the 3rd floor, and the division will continue to be called the advertising department.\n",
      "Reference : 남은 직원들은 3층 현재 자리에 남을 것이고, 부서는 계속 광고 부서로 불린다고 하네요.\n",
      "Translated: 나머지 직원들은 현재 3층 공간에 머무르며, 이 부서는 계속 광고 부서라고 불리게 된다.\n",
      "\n",
      "\n",
      "English   : I have a question about the year-end tax adjustment.\n",
      "Reference : 이번 연말 정산 관련해서 질문이 있어요.\n",
      "Translated: 저는 연말정산에 대해 궁금한 점이 있습니다.\n",
      "\n",
      "\n",
      "English   : Is there any problem?\n",
      "Reference : 무슨 문제라도 있으신가요?\n",
      "Translated: 혹시 문제가 있나요?\n",
      "\n",
      "\n",
      "English   : I am registering my dependent this time, so do I need to submit any particular documents?\n",
      "Reference : 제가 이번에 부양가족을 등록하려고 하는데, 따로 제출해야 하는 서류가 있나요?\n",
      "Translated: 이번에 제 부양가족 등록을 하는데, 특별히 서류 제출이 필요한가요?\n",
      "\n",
      "\n",
      "English   : No, please refer to the form I sent to all employees and fill in the contents.\n",
      "Reference : 아닙니다, 제가 단체 이메일로 보내드린 서류를 참조해서 내용을 넣어주시면 됩니다.\n",
      "Translated: 아니요, 제가 모든 직원에게 보낸 양식을 참고하여 내용을 작성해주세요.\n",
      "\n",
      "\n",
      "English   : Are all production reports ready this month?\n",
      "Reference : 이번 달 프로덕션 리포트는 모두 준비되었나요?\n",
      "Translated: 이번 달에 모든 생산 보고서가 준비되었나요?\n",
      "\n",
      "\n",
      "English   : James is preparing now, but he hasn't finished it yet.\n",
      "Reference : James가 지금 준비 중인데, 아직 완료하지 못했습니다.\n",
      "Translated: 제임스는 지금 준비 중이지만 아직 완성하지 못했습니다.\n",
      "\n",
      "\n",
      "English   : What's the reason for the delay?\n",
      "Reference : 늦춰지는 이유가 무엇인가요?\n",
      "Translated: 지연된 이유는 무엇인가요?\n",
      "\n",
      "\n",
      "English   : He said that he noticed errors in the figures and has to reprint some pages.\n",
      "Reference : 그는 수치에서 오류를 발견했고 몇 페이지를 다시 인쇄해야 한다고 말했어요.\n",
      "Translated: 그는 수치에 오류가 생겨 일부 페이지를 수정해야 한다고 했다.\n",
      "\n",
      "\n",
      "English   : Did you make a total of ten samples?\n",
      "Reference : 샘플을 총 열 개 만드신 거예요?\n",
      "Translated: 당신은 총 10개의 샘플을 만드셨나요?\n",
      "\n",
      "\n",
      "English   : Yes, I want to make sales more aggressively at this meeting.\n",
      "Reference : 네, 이번 미팅에서는 조금 더 공격적으로 영업해 보고 싶습니다.\n",
      "Translated: 네, 이번 회의에서 더 공격적으로 판매를 하고 싶습니다.\n",
      "\n",
      "\n",
      "English   : Great, but the sample room was full yesterday, how did you make them?\n",
      "Reference : 대단하세요, 그런데 어제 샘플실 예약이 꽉 찼던데, 어떻게 만드신 거예요?\n",
      "Translated: 예, 근데 어제 샘플룸이 가득했는데 어떻게 만들었나요?\n",
      "\n",
      "\n",
      "English   : So I contacted our subcontractor in a hurry.\n",
      "Reference : 그래서 급하게 하청업체에 도움을 청해 보았어요.\n",
      "Translated: 그래서 급하게 하청업체에 연락했습니다.\n",
      "\n",
      "\n",
      "English   : You are well prepared for this meeting.\n",
      "Reference : 이번 미팅 준비를 단단히 하셨네요.\n",
      "Translated: 당신은 이번 미팅에 준비가 잘 되어 있습니다.\n",
      "\n",
      "\n",
      "English   : Yes, we also have three volumes of fabric files for this season.\n",
      "Reference : 네, 이번 시즌 원단 파일도 3권이나 준비했습니다.\n",
      "Translated: 네, 이번 시즌 원단 파일도 3권 가지고 있습니다.\n",
      "\n",
      "\n",
      "English   : Buyers will be happy to see various samples at the meeting.\n",
      "Reference : 바이어가 미팅 때 다양한 샘플들을 보고 만족할 것 같아요.\n",
      "Translated: 바이어들은 미팅에서 다양한 샘플을 볼 수 있어 행복할 것이에요.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_dataloader_iter = iter(test_dataloader)\n",
    "test_batch = next(test_dataloader_iter)\n",
    "test_batch.keys()\n",
    "test_input = { key: test_batch[key] for key in ('input_ids', 'attention_mask') }\n",
    "koreans = model.generate(\n",
    "    **test_input,\n",
    "    max_length=max_token_length,\n",
    "    num_beams=5,\n",
    ")\n",
    "labels =  np.where(test_batch.labels != -100, test_batch.labels, tokenizer.pad_token_id)\n",
    "eng_sents = tokenizer.batch_decode(test_batch.input_ids, skip_special_tokens=True)[0:1000]\n",
    "references = tokenizer.batch_decode(labels, skip_special_tokens=True)[0:1000]\n",
    "preds = tokenizer.batch_decode( koreans, skip_special_tokens=True )[0:1000]\n",
    "\n",
    "for s in zip(eng_sents, references, preds):\n",
    "    print('English   :', s[0])\n",
    "    print('Reference :', s[1])\n",
    "    print('Translated:', s[2])\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU : 15.007608917450117\n"
     ]
    }
   ],
   "source": [
    "score = []\n",
    "for i in range(len(preds)):\n",
    "    s = metric.compute(predictions=[preds[i]], references=[references[i]])\n",
    "    score.append(s['score'])\n",
    "print('BLEU :' , np.mean(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
